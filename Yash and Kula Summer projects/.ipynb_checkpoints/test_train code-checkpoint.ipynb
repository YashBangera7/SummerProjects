{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vari1= ig.open('/Users/kulasekharmaganti/SummerProjects/Yash and Kula Summer projects/emotion detection dataset/test/angry/im87.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=48x48 at 0x7FCD2EF883D0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vari1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = vari1.getdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ImagingCore at 0x7fcd34cb4f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304,)\n"
     ]
    }
   ],
   "source": [
    "print(img_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_arr = img_arr/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156862745098039"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(ig_arr)\n",
    "np.max(ig_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion detection dataset',\n",
       " '.DS_Store',\n",
       " 'Untitled.ipynb',\n",
       " 'test_train code.ipynb',\n",
       " 'PILimage.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "path = os.listdir('emotion detection dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = 'emotion detection dataset' + '/' + path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'emotion detection dataset' + '/' + path[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emotion detection dataset/test'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy',\n",
       " '.DS_Store',\n",
       " 'sad',\n",
       " 'fearful',\n",
       " 'neutral',\n",
       " 'angry',\n",
       " 'disgusted',\n",
       " 'surprised']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'sad', 'fearful', 'neutral', 'angry', 'disgusted', 'surprised']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    temp_path = path_train + '/' + classes[i]\n",
    "    current_image_path = os.listdir(temp_path)\n",
    "    for j in range(len(current_image_path)):\n",
    "        if current_image_path[j]=='.DS_Store':\n",
    "            pass\n",
    "        else:\n",
    "            current_image = np.array(ig.open(temp_path + '/' + current_image_path[j]).getdata())\n",
    "            X_train.append(current_image)\n",
    "            y_train.append(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    temp_path = path_test + '/' + classes[i]\n",
    "    current_image_path = os.listdir(temp_path)\n",
    "    for j in range(len(current_image_path)):\n",
    "        if current_image_path[j]=='.DS_Store':\n",
    "            pass\n",
    "        else:\n",
    "            current_image = np.array(ig.open(temp_path + '/' + current_image_path[j]).getdata())\n",
    "            X_test.append(current_image)\n",
    "            y_test.append(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7178"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7178"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28709"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28709"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'sad', 'fearful', 'neutral', 'angry', 'disgusted', 'surprised']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "for i in range(len(y_train)):\n",
    "    if (y_train[i]=='happy'):\n",
    "        y_train_new.append(0)\n",
    "    elif (y_train[i]=='sad'):\n",
    "        y_train_new.append(1)\n",
    "    elif (y_train[i]=='fearful'):\n",
    "        y_train_new.append(2)\n",
    "    elif (y_train[i]=='neutral'):\n",
    "        y_train_new.append(3)\n",
    "    elif (y_train[i]=='angry'):\n",
    "        y_train_new.append(4)\n",
    "    elif (y_train[i]=='disgusted'):\n",
    "        y_train_new.append(5)\n",
    "    elif (y_train[i]=='surprised'):\n",
    "        y_train_new.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new = []\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i]=='happy'):\n",
    "        y_test_new.append(0)\n",
    "    elif (y_test[i]=='sad'):\n",
    "        y_test_new.append(1)\n",
    "    elif (y_test[i]=='fearful'):\n",
    "        y_test_new.append(2)\n",
    "    elif (y_test[i]=='neutral'):\n",
    "        y_test_new.append(3)\n",
    "    elif (y_test[i]=='angry'):\n",
    "        y_test_new.append(4)\n",
    "    elif (y_test[i]=='disgusted'):\n",
    "        y_test_new.append(5)\n",
    "    elif (y_test[i]=='surprised'):\n",
    "        y_test_new.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after one-hot encoding:  (28709, 7)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train_new, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test_new, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28709"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (28709,2304)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape = ()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7178"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the input vector from the 48x48 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               230500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 231,207\n",
      "Trainable params: 231,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_7 is incompatible with the layer: expected axis -1 of input shape to have value 2304 but received input with shape [None, 48, 48, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-9ccfecdcf9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# training the model for 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_7 is incompatible with the layer: expected axis -1 of input shape to have value 2304 but received input with shape [None, 48, 48, 1]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# hidden layer\n",
    "model.add(Dense(100, input_shape=(2304,), activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# looking at the model summary\n",
    "model.summary()\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "225/225 [==============================] - 32s 143ms/step - loss: 1.8101 - accuracy: 0.2500 - val_loss: 1.8834 - val_accuracy: 0.1737\n",
      "Epoch 2/45\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 1.7680 - accuracy: 0.2671 - val_loss: 2.0023 - val_accuracy: 0.1737\n",
      "Epoch 3/45\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 1.7191 - accuracy: 0.3080 - val_loss: 2.1445 - val_accuracy: 0.1737\n",
      "Epoch 4/45\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 1.6748 - accuracy: 0.3400 - val_loss: 2.1753 - val_accuracy: 0.1737\n",
      "Epoch 5/45\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 1.6552 - accuracy: 0.3542 - val_loss: 2.1718 - val_accuracy: 0.1737\n",
      "Epoch 6/45\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 1.6430 - accuracy: 0.3575 - val_loss: 2.2315 - val_accuracy: 0.1737\n",
      "Epoch 7/45\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 1.6314 - accuracy: 0.3647 - val_loss: 2.2114 - val_accuracy: 0.1737\n",
      "Epoch 8/45\n",
      "225/225 [==============================] - 40s 179ms/step - loss: 1.6233 - accuracy: 0.3701 - val_loss: 2.1325 - val_accuracy: 0.1737\n",
      "Epoch 9/45\n",
      "225/225 [==============================] - 61s 272ms/step - loss: 1.6128 - accuracy: 0.3767 - val_loss: 2.2298 - val_accuracy: 0.1737\n",
      "Epoch 10/45\n",
      "225/225 [==============================] - 48s 212ms/step - loss: 1.6054 - accuracy: 0.3769 - val_loss: 2.0550 - val_accuracy: 0.1737\n",
      "Epoch 11/45\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 1.5979 - accuracy: 0.3817 - val_loss: 2.0884 - val_accuracy: 0.1737\n",
      "Epoch 12/45\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 1.5868 - accuracy: 0.3851 - val_loss: 2.1898 - val_accuracy: 0.1737\n",
      "Epoch 13/45\n",
      "225/225 [==============================] - 43s 189ms/step - loss: 1.5781 - accuracy: 0.3867 - val_loss: 2.2727 - val_accuracy: 0.1737\n",
      "Epoch 14/45\n",
      "225/225 [==============================] - 39s 173ms/step - loss: 1.5662 - accuracy: 0.3949 - val_loss: 2.2021 - val_accuracy: 0.1737\n",
      "Epoch 15/45\n",
      "225/225 [==============================] - 44s 194ms/step - loss: 1.5558 - accuracy: 0.3975 - val_loss: 2.2635 - val_accuracy: 0.1737\n",
      "Epoch 16/45\n",
      "225/225 [==============================] - 42s 187ms/step - loss: 1.5484 - accuracy: 0.4018 - val_loss: 2.0694 - val_accuracy: 0.1737\n",
      "Epoch 17/45\n",
      "225/225 [==============================] - 43s 189ms/step - loss: 1.5399 - accuracy: 0.4067 - val_loss: 2.2116 - val_accuracy: 0.1737\n",
      "Epoch 18/45\n",
      "225/225 [==============================] - 42s 187ms/step - loss: 1.5330 - accuracy: 0.4088 - val_loss: 2.1490 - val_accuracy: 0.1737\n",
      "Epoch 19/45\n",
      "225/225 [==============================] - 42s 185ms/step - loss: 1.5246 - accuracy: 0.4110 - val_loss: 2.1531 - val_accuracy: 0.1737\n",
      "Epoch 20/45\n",
      "225/225 [==============================] - 42s 185ms/step - loss: 1.5192 - accuracy: 0.4139 - val_loss: 2.2152 - val_accuracy: 0.1737\n",
      "Epoch 21/45\n",
      "225/225 [==============================] - 41s 184ms/step - loss: 1.5104 - accuracy: 0.4177 - val_loss: 2.1535 - val_accuracy: 0.1737\n",
      "Epoch 22/45\n",
      "225/225 [==============================] - 43s 190ms/step - loss: 1.5058 - accuracy: 0.4217 - val_loss: 2.2432 - val_accuracy: 0.1737\n",
      "Epoch 23/45\n",
      "225/225 [==============================] - 41s 180ms/step - loss: 1.4993 - accuracy: 0.4241 - val_loss: 2.2242 - val_accuracy: 0.1737\n",
      "Epoch 24/45\n",
      "225/225 [==============================] - 39s 173ms/step - loss: 1.4923 - accuracy: 0.4270 - val_loss: 2.1607 - val_accuracy: 0.1737\n",
      "Epoch 25/45\n",
      "225/225 [==============================] - 40s 176ms/step - loss: 1.4866 - accuracy: 0.4270 - val_loss: 2.2282 - val_accuracy: 0.1737\n",
      "Epoch 26/45\n",
      "225/225 [==============================] - 40s 176ms/step - loss: 1.4805 - accuracy: 0.4308 - val_loss: 2.2557 - val_accuracy: 0.1737\n",
      "Epoch 27/45\n",
      "225/225 [==============================] - 38s 167ms/step - loss: 1.4739 - accuracy: 0.4321 - val_loss: 2.2037 - val_accuracy: 0.1737\n",
      "Epoch 28/45\n",
      "225/225 [==============================] - 39s 172ms/step - loss: 1.4674 - accuracy: 0.4370 - val_loss: 2.1870 - val_accuracy: 0.1335\n",
      "Epoch 29/45\n",
      "225/225 [==============================] - 38s 170ms/step - loss: 1.4610 - accuracy: 0.4379 - val_loss: 2.3757 - val_accuracy: 0.1737\n",
      "Epoch 30/45\n",
      "225/225 [==============================] - 38s 171ms/step - loss: 1.4577 - accuracy: 0.4415 - val_loss: 2.2613 - val_accuracy: 0.1737\n",
      "Epoch 31/45\n",
      "225/225 [==============================] - 38s 171ms/step - loss: 1.4507 - accuracy: 0.4420 - val_loss: 2.1704 - val_accuracy: 0.1737\n",
      "Epoch 32/45\n",
      "225/225 [==============================] - 38s 168ms/step - loss: 1.4473 - accuracy: 0.4455 - val_loss: 2.1543 - val_accuracy: 0.1737\n",
      "Epoch 33/45\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 1.4360 - accuracy: 0.4497 - val_loss: 2.2467 - val_accuracy: 0.1737\n",
      "Epoch 34/45\n",
      "225/225 [==============================] - 39s 174ms/step - loss: 1.4330 - accuracy: 0.4501 - val_loss: 2.3120 - val_accuracy: 0.1737\n",
      "Epoch 35/45\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 1.4274 - accuracy: 0.4543 - val_loss: 2.1809 - val_accuracy: 0.1406\n",
      "Epoch 36/45\n",
      "225/225 [==============================] - 36s 158ms/step - loss: 1.4216 - accuracy: 0.4554 - val_loss: 2.1578 - val_accuracy: 0.1718\n",
      "Epoch 37/45\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 1.4180 - accuracy: 0.4568 - val_loss: 2.1975 - val_accuracy: 0.1737\n",
      "Epoch 38/45\n",
      "225/225 [==============================] - 43s 190ms/step - loss: 1.4122 - accuracy: 0.4590 - val_loss: 2.1952 - val_accuracy: 0.1335\n",
      "Epoch 39/45\n",
      "225/225 [==============================] - 42s 185ms/step - loss: 1.4071 - accuracy: 0.4622 - val_loss: 2.1123 - val_accuracy: 0.1737\n",
      "Epoch 40/45\n",
      "225/225 [==============================] - 40s 176ms/step - loss: 1.3998 - accuracy: 0.4654 - val_loss: 2.1169 - val_accuracy: 0.1737\n",
      "Epoch 41/45\n",
      "225/225 [==============================] - 42s 189ms/step - loss: 1.3969 - accuracy: 0.4678 - val_loss: 2.1243 - val_accuracy: 0.1737\n",
      "Epoch 42/45\n",
      "225/225 [==============================] - 38s 168ms/step - loss: 1.3925 - accuracy: 0.4667 - val_loss: 2.0266 - val_accuracy: 0.1737\n",
      "Epoch 43/45\n",
      "225/225 [==============================] - 40s 178ms/step - loss: 1.3852 - accuracy: 0.4720 - val_loss: 2.1352 - val_accuracy: 0.1737\n",
      "Epoch 44/45\n",
      "225/225 [==============================] - 46s 204ms/step - loss: 1.3834 - accuracy: 0.4704 - val_loss: 2.0789 - val_accuracy: 0.1737\n",
      "Epoch 45/45\n",
      "225/225 [==============================] - 38s 171ms/step - loss: 1.3749 - accuracy: 0.4777 - val_loss: 2.1350 - val_accuracy: 0.1718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbac876690>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADDED FIRST CONVOLUTION LAYER\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=45, validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "225/225 [==============================] - 222s 988ms/step - loss: 1.8240 - accuracy: 0.2463 - val_loss: 1.8136 - val_accuracy: 0.2471\n",
      "Epoch 2/5\n",
      " 54/225 [======>.......................] - ETA: 2:52 - loss: 1.8107 - accuracy: 0.2551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-6fbb05a6dda8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# training the model for 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ADDED MORE CONVOLUTION LAYER\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layer\n",
    "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(48,48,1)))\n",
    "\n",
    "# convolutional layer\n",
    "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "yashhappy= ig.open('/Users/kulasekharmaganti/SummerProjects/Yash and Kula Summer projects/emotion detection dataset/test/fearful/im17.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_arr = np.array(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 2304)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "img11_arr = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(array):\n",
    "    prediction = []\n",
    "    for i in range(len(array)):\n",
    "        if (np.argmax(array[i])==0):\n",
    "            prediction.append('happy')\n",
    "        elif (np.argmax(array[i])==1):\n",
    "            prediction.append('sad')\n",
    "        elif (np.argmax(array[i])==2):\n",
    "            prediction.append('fearful')\n",
    "        elif (np.argmax(array[i])==3):\n",
    "            prediction.append('neutral')\n",
    "        elif (np.argmax(array[i])==4):\n",
    "            prediction.append('angry')\n",
    "        elif (np.argmax(array[i])==5):\n",
    "            prediction.append('disgusted')\n",
    "        elif (np.argmax(array[i])==6):\n",
    "            prediction.append('surprised')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        ... 0.        0.        1.       ]\n",
      " [0.9997125 0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        1.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        1.       ]\n",
      " [0.        0.        0.        ... 0.        0.        1.       ]\n",
      " [0.        0.        0.        ... 0.        0.        1.       ]]\n"
     ]
    }
   ],
   "source": [
    "array = model.predict(img11_arr)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = prediction(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " ...]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.02      0.23      0.04        88\n",
      "   disgusted       0.00      0.00      0.00        11\n",
      "     fearful       0.03      0.16      0.05       179\n",
      "       happy       0.31      0.44      0.37      1252\n",
      "     neutral       0.20      0.19      0.20      1271\n",
      "         sad       0.02      0.32      0.03        66\n",
      "   surprised       0.81      0.16      0.26      4311\n",
      "\n",
      "    accuracy                           0.21      7178\n",
      "   macro avg       0.20      0.21      0.13      7178\n",
      "weighted avg       0.58      0.21      0.26      7178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
